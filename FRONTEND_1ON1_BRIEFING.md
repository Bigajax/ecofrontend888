# ğŸ¤ SSE Backend - Briefing para Frontend (1 on 1)

## Intro

Hey! Fiz algumas melhorias importantes no SSE do `/api/ask-eco`. Nada quebra o que vocÃªs tÃªm hoje, mas preciso de uma pequena mudanÃ§a no frontend para ficarem bulletproof. Deixe-me explicar:

---

## ğŸ“º O Problema que TÃ­nhamos

### Sintomas que vocÃªs provavelmente viram:
```
âŒ "ready_timeout" - conexÃ£o SSE demora pra ficar ready
âŒ "5s sem chunks" - parece que travou, mas backend tÃ¡ mandando dados
âŒ Duplicated streams - cliente manda 2 mensagens rÃ¡pido, bagunÃ§a tudo
âŒ Chunks chegando DEPOIS do "done" poluindo a resposta
```

### Por quÃª acontecia?
1. **Prompt ready emitido DUAS vezes** (uma sem streamId, outra com)
2. **Sem forma de o frontend saber qual stream Ã© qual** (sem streamId consistente)
3. **Heartbeat Ã s vezes falhava** (nÃ£o prevenia timeout)
4. **ImpossÃ­vel filtrar eventos Ã³rfÃ£os** (de streams antigos)

---

## âœ… O Que Eu Fixei

### 1ï¸âƒ£ Removi DuplicaÃ§Ã£o
```
ANTES:
  event: prompt_ready (SEM streamId) âŒ
  event: stream_metadata (com streamId) âŒ
  event: prompt_ready AGAIN (com streamId) âŒ â† Duplicate!

DEPOIS:
  event: control (name: "prompt_ready", com streamId) âœ…
  (uma Ãºnica, correta, completa)
```

### 2ï¸âƒ£ Todos os Eventos Agora TÃªm streamId
```json
{
  "type": "prompt_ready",
  "streamId": "550e8400-e29b-41d4-a716-446655440000",
  "client_message_id": "...",
  "at": 1699564800000
}
```

**Todos os tipos tÃªm isso agora:**
- âœ… prompt_ready
- âœ… chunk
- âœ… done
- âœ… memory_saved
- âœ… error

### 3ï¸âƒ£ Heartbeat Funcionando Corretamente
```
A cada 12 segundos:
  :keepalive

Isso mantÃ©m a conexÃ£o viva mesmo durante
processamento longo do LLM (>30s)
```

### 4ï¸âƒ£ Headers Sem Buffer
```
X-Accel-Buffering: no
Cache-Control: no-cache, no-transform
```
Isso garante que proxy (Nginx, Cloudflare) nÃ£o bufferiza os chunks.

---

## ğŸ¯ O Que VocÃªs Precisam Fazer

### MudanÃ§a MÃ­nima - SÃ³ Isso:

**Capturar o streamId e filtrar eventos:**

```typescript
// 1. Captura streamId da response header
const streamId = response.headers.get('x-stream-id');
console.log('Stream ID:', streamId);

// 2. Quando receber um evento SSE:
eventSource.addEventListener('chunk', (event) => {
  const data = JSON.parse(event.data);

  // NOVO: Ignora eventos de streams antigos/Ã³rfÃ£os
  if (data.streamId !== streamId) {
    console.warn('Ignorando evento de stream antigo:', data.streamId);
    return;
  }

  // Processa normalmente
  handleChunk(data);
});
```

### Por quÃª?
Quando o usuÃ¡rio manda 2 mensagens rapidamente:
- Primeira stream comeÃ§a
- Segunda stream chega e substitui a primeira
- Primeira stream recebe: `finish_reason: "replaced_by_new_stream"`
- Eventos da primeira podem chegar depois do "done" da segunda

**Com streamId, vocÃª ignora os eventos "atrasados" da primeira.**

---

## ğŸ’» Exemplo PrÃ¡tico - Antes vs Depois

### ANTES (problemÃ¡tico)
```typescript
async function sendMessage(message: string) {
  const response = await fetch('/api/ask-eco', {
    method: 'POST',
    body: JSON.stringify({ message })
  });

  const reader = response.body.getReader();

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    const text = new TextDecoder().decode(value);
    const lines = text.split('\n');

    for (const line of lines) {
      if (line.startsWith('data: ')) {
        const event = JSON.parse(line.slice(6));

        // âŒ PROBLEMA: Recebe eventos de streams antigos
        // âŒ Se mandar 2 mensagens rÃ¡pido, chunks se misturam
        handleEvent(event);
      }
    }
  }
}
```

### DEPOIS (robusto)
```typescript
async function sendMessage(message: string) {
  const response = await fetch('/api/ask-eco', {
    method: 'POST',
    body: JSON.stringify({ message })
  });

  // âœ… NOVO: Captura streamId
  const streamId = response.headers.get('x-stream-id');
  if (!streamId) {
    throw new Error('Server did not provide streamId');
  }

  const reader = response.body.getReader();

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    const text = new TextDecoder().decode(value);
    const lines = text.split('\n');

    for (const line of lines) {
      if (line.startsWith('data: ')) {
        const event = JSON.parse(line.slice(6));

        // âœ… NOVO: Filtra por streamId
        if (event.streamId !== streamId) {
          console.debug('Ignorando evento de stream antigo');
          return;
        }

        handleEvent(event);
      }
    }
  }
}
```

---

## ğŸ§ª Como Testar

### Teste 1: Verificar que Ã© Uma Ãšnica prompt_ready
```bash
curl -X POST http://localhost:3001/api/ask-eco \
  -H "Content-Type: application/json" \
  -d '{"message":"Hi","clientMessageId":"test"}' \
  --no-buffer 2>&1 | grep -c "prompt_ready"
```
**Esperado**: `1` (somente uma)

### Teste 2: Verificar streamId no Header
```bash
curl -i -X POST http://localhost:3001/api/ask-eco \
  -H "Content-Type: application/json" \
  -d '{"message":"Hi","clientMessageId":"test"}' 2>&1 | grep x-stream-id
```
**Esperado**:
```
x-stream-id: 550e8400-e29b-41d4-a716-446655440000
```

### Teste 3: Verificar streamId em Todos os Eventos
```bash
curl -X POST http://localhost:3001/api/ask-eco \
  -H "Content-Type: application/json" \
  -d '{"message":"Hi","clientMessageId":"test"}' \
  --no-buffer 2>&1 | grep -o '"streamId"' | wc -l
```
**Esperado**: Muitos matches (mÃºltiplos eventos com streamId)

### Teste 4: Testar Duplicate Streams
```bash
# Manda 2 mensagens rÃ¡pido no frontend
1. Clica em "enviar" com "Mensagem 1"
2. Imediatamente (antes de receber resposta) clica em "enviar" com "Mensagem 2"

Esperado:
- Mensagem 1 inicia a stream
- Mensagem 2 chega e substitui
- Mensagem 1 recebe: finish_reason: "replaced_by_new_stream" (SEM ERRO)
- Mensagem 2 continua normalmente
- Nenhum erro no console
```

---

## ğŸ” O Que Muda e O Que NÃ£o Muda

### âœ… NÃƒO MUDA (backward compatible)
```
- Tipos de eventos: prompt_ready, chunk, done, etc. (IGUAIS)
- Estrutura JSON: (IGUAL)
- Response headers: (IGUAIS, agora com x-stream-id)
- Formatos: (IGUAIS)
- Nenhuma lib precisa atualizar
- CÃ³digo existente continua funcionando
```

### âš ï¸ MUDA (melhoria)
```
- Cada evento agora tem streamId (novo campo)
- VocÃª pode filtrÃ¡-los por streamId (novo)
- prompt_ready nÃ£o duplica mais (melhoria)
- Heartbeat mais consistente (melhoria)
```

---

## ğŸš¨ Edge Cases Que VocÃª Pode Ver

### CenÃ¡rio 1: UsuÃ¡rio envia 2 mensagens rÃ¡pido
```
Timeline:
T=0ms   â†’ Msg 1 enviada (streamId: AAA)
T=50ms  â†’ Msg 2 enviada (streamId: BBB)
T=100ms â†’ AAA recebe: event: chunk (streamId: AAA)
T=150ms â†’ BBB recebe: event: chunk (streamId: BBB)
T=200ms â†’ AAA recebe: event: done (finish_reason: "replaced_by_new_stream")
T=250ms â†’ BBB recebe: event: chunk (streamId: BBB)
T=300ms â†’ BBB recebe: event: done (finish_reason: "stop")

Seu cÃ³digo (com filtro):
- T=100: Processa (streamId AAA === streamId no header? Sim, processa)
  Mas ESPERA, streamId muda em T=50!

IMPORTANTE: VocÃª precisa ATUALIZAR o streamId quando manda nova msg!
```

**SoluÃ§Ã£o**:
```typescript
async function sendMessage(message: string) {
  // âœ… Captura novo streamId ANTES de processar
  const response = await fetch('/api/ask-eco', {...});
  const newStreamId = response.headers.get('x-stream-id');

  // âœ… Atualiza a variÃ¡vel
  currentStreamId = newStreamId;

  // Agora processa com newStreamId
  const reader = response.body.getReader();
  // ... resto do cÃ³digo filtra por currentStreamId
}
```

### CenÃ¡rio 2: ConexÃ£o cai e volta
```
1. Mensagem em progresso, conexÃ£o cai
2. UsuÃ¡rio quer reenviar
3. VocÃª precisa cancelar a antiga (AbortController)

CÃ³digo:
let abortController = null;

function sendMessage(message: string) {
  if (abortController) {
    abortController.abort(); // Cancela requisiÃ§Ã£o antiga
  }

  abortController = new AbortController();

  fetch('/api/ask-eco', {
    signal: abortController.signal,
    ...
  });
}
```

### CenÃ¡rio 3: VÃª eventos de tipo "control"
```json
{
  "type": "control",
  "name": "prompt_ready",
  "streamId": "...",
  ...
}
```

**Isso Ã© normal.** Eventos de controle (prompt_ready, etc) vÃªm como `type: "control"` com um campo `name` indicando qual controle.

---

## ğŸ“‹ Checklist pro Frontend

- [ ] Capturar `x-stream-id` do header de response
- [ ] Filtrar eventos por `streamId` para ignorar eventos Ã³rfÃ£os
- [ ] Atualizar `currentStreamId` quando nova mensagem Ã© enviada
- [ ] Usar `AbortController` para cancelar requisiÃ§Ãµes antigas
- [ ] Testar com 2 mensagens enviadas rapidamente
- [ ] Testar com conexÃ£o lenta (DevTools > Throttling)
- [ ] Verificar que nÃ£o hÃ¡ eventos duplicados no console
- [ ] Verificar que "replaced_by_new_stream" nÃ£o causa erro
- [ ] Carregar a pÃ¡gina novamente e testar

---

## ğŸ¬ Exemplo Completo (React Hook)

```typescript
import { useEffect, useState, useRef } from 'react';

function useEcoStream(message: string) {
  const [response, setResponse] = useState('');
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const abortControllerRef = useRef<AbortController | null>(null);
  const currentStreamIdRef = useRef<string | null>(null);

  useEffect(() => {
    if (!message.trim()) return;

    // Cancela requisiÃ§Ã£o anterior se ainda tiver rodando
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
    }

    setLoading(true);
    setError(null);
    setResponse('');

    const abortController = new AbortController();
    abortControllerRef.current = abortController;

    const clientMessageId = `msg-${Date.now()}-${Math.random().toString(36).slice(2)}`;

    fetch('/api/ask-eco', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ message, clientMessageId }),
      signal: abortController.signal,
    })
      .then((response) => {
        // âœ¨ NOVO: Captura streamId
        const streamId = response.headers.get('x-stream-id');
        if (!streamId) {
          throw new Error('No stream ID from server');
        }
        currentStreamIdRef.current = streamId;
        console.log('[useEcoStream] streamId:', streamId);

        if (!response.body) {
          throw new Error('No response body');
        }

        const reader = response.body.getReader();
        const decoder = new TextDecoder();
        let buffer = '';

        const processChunk = async () => {
          try {
            const { done, value } = await reader.read();
            if (done) return;

            buffer += decoder.decode(value, { stream: true });
            const lines = buffer.split('\n');
            buffer = lines.pop() || '';

            for (const line of lines) {
              if (!line.trim() || line.startsWith(':')) {
                // Ignora linhas vazias e comentÃ¡rios (heartbeat)
                continue;
              }

              if (line.startsWith('data: ')) {
                try {
                  const event = JSON.parse(line.slice(6));

                  // âœ¨ NOVO: Filtra por streamId
                  if (event.streamId !== currentStreamIdRef.current) {
                    console.debug(
                      '[useEcoStream] Ignorando evento de stream antigo:',
                      event.streamId
                    );
                    return;
                  }

                  // Processa o evento
                  if (event.type === 'chunk' || event.name === 'chunk') {
                    setResponse((prev) => prev + (event.delta || ''));
                  } else if (event.type === 'done' || event.name === 'done') {
                    console.log('[useEcoStream] Stream completo');
                  } else if (
                    event.type === 'prompt_ready' ||
                    event.name === 'prompt_ready'
                  ) {
                    console.log('[useEcoStream] prompt_ready recebido');
                  }
                } catch (parseError) {
                  console.error('[useEcoStream] Failed to parse event:', line);
                }
              }
            }

            return processChunk();
          } catch (error) {
            if (error instanceof Error && error.name === 'AbortError') {
              console.log('[useEcoStream] Stream cancelled by user');
              return;
            }
            throw error;
          }
        };

        return processChunk();
      })
      .catch((err) => {
        if (err instanceof Error && err.name === 'AbortError') {
          console.log('[useEcoStream] Request aborted');
        } else {
          setError(err instanceof Error ? err.message : 'Unknown error');
          console.error('[useEcoStream] Error:', err);
        }
      })
      .finally(() => {
        setLoading(false);
      });
  }, [message]);

  return { response, loading, error };
}

// Uso
export function ChatApp() {
  const [input, setInput] = useState('');
  const [messages, setMessages] = useState<string[]>([]);
  const { response, loading } = useEcoStream(messages[messages.length - 1] || '');

  const handleSend = () => {
    if (input.trim()) {
      setMessages([...messages, input]);
      setInput('');
    }
  };

  return (
    <div>
      <div className="chat-messages">
        {messages.map((msg, i) => (
          <div key={i}>
            <p><strong>You:</strong> {msg}</p>
            {i === messages.length - 1 && (
              <p><strong>Eco:</strong> {response || (loading ? 'Thinking...' : '')}</p>
            )}
          </div>
        ))}
      </div>
      <input
        value={input}
        onChange={(e) => setInput(e.target.value)}
        onKeyPress={(e) => e.key === 'Enter' && handleSend()}
        placeholder="Type a message..."
      />
      <button onClick={handleSend} disabled={loading}>
        Send
      </button>
    </div>
  );
}
```

---

## â“ FAQ

**P: Preciso mudar todo o meu cÃ³digo?**
R: NÃ£o. SÃ³ adiciona o filtro por streamId. 5 linhas de cÃ³digo.

**P: E se eu nÃ£o colocar o filtro?**
R: Vai funcionar 99% das vezes. Mas com 2 mensagens rÃ¡pidas, vai misturar chunks.

**P: O heartbeat (`:keepalive`) Ã© normal?**
R: Sim! Ã‰ um comentÃ¡rio SSE. Seu parser deve ignorar (linhas comeÃ§ando com `:`).

**P: Por que "replaced_by_new_stream" nÃ£o Ã© um erro?**
R: Porque Ã© esperado! Quando vocÃª manda nova msg, a antiga Ã© substituÃ­da gracefully.

**P: Meus timeouts vÃ£o continuar iguais?**
R: Sim. Mas agora mais robusto - heartbeat a cada 12s previne falsos timeouts.

**P: Preciso fazer rebuild?**
R: Frontend: nÃ£o. Backend: precisa fazer `npm run build` se ainda nÃ£o fez.

**P: Quando vocÃªs vÃ£o liberar no prod?**
R: Quando vocÃªs tiverem testado e aprovado. Avisa quando estiver pronto!

---

## ğŸ“ PrÃ³ximos Passos

1. **VocÃªs**: Implementam o filtro de streamId
2. **VocÃªs**: Testam conforme os testes acima
3. **VocÃªs**: Avisa se encontrou algo estranho
4. **Eu**: FaÃ§o qualquer ajuste se precisar
5. **Deploy**: Primeiro backend, depois frontend

---

## ğŸ“š Docs de ReferÃªncia

Se precisa de mais detalhes, tem 3 docs:

1. **SSE_FRONTEND_INTEGRATION.md** - Exemplos mais detalhados
2. **SSE_TESTING_GUIDE.md** - Como testar tudo
3. **SSE_ROBUSTNESS_FIXES.md** - O que exatamente mudou no backend

Mas honestamente? Essa doc aqui jÃ¡ tem 90% do que vocÃªs precisam.

---

**Ã‰ isso!** Bora fazer isso rodar. ğŸš€

Alguma dÃºvida? Me chama no Slack!
